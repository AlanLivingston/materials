{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiny Statistics Review\n",
    "\n",
    "What is a distribution and what is a standard deviation?\n",
    "\n",
    "Let's look to [this resource](https://www.mathsisfun.com/data/standard-normal-distribution.html) from Math is Fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals\n",
    "\n",
    ">The 95% confidence interval is a range of values that you can be 95% certain contains the true mean of the population. As the sample size increases, the range of interval values will narrow, meaning that you know that mean with much more accuracy compared with a smaller sample.\n",
    "\n",
    "- [Simply Psychology](https://www.simplypsychology.org/confidence-interval.html)\n",
    "\n",
    "Typically we use the normal distribution for calculating confidence intervals when we have more than 120 samples. However, for really small numbers of samples (under 120), we can use the wider, flatter [t-distribution](https://www.statisticshowto.com/probability-and-statistics/t-distribution/), which _looks like_ the normal distribution at and above about 120 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scipy \n",
    "\n",
    "import math\n",
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "\n",
    "def confidence_interval_for_collection(sample_size=[], standard_deviation=[], mean=[], confidence=0.95):\n",
    "    degrees_freedom = [count - 1 for count in sample_size]\n",
    "    outlier_tails = (1.0 - confidence) / 2.0\n",
    "    confidence_collection = [outlier_tails for _ in sample_size]\n",
    "    t_distribution_number = [-1 * t.ppf(tails, df) for tails, df in zip(confidence_collection, degrees_freedom)]\n",
    "\n",
    "    step_1 = [std/math.sqrt(count) for std, count in zip(standard_deviation, sample_size)]\n",
    "    step_2 = [step * t for step, t in zip(step_1, t_distribution_number)]\n",
    "\n",
    "    low_end = [mean_num - step_num for mean_num, step_num in zip(mean, step_2)]\n",
    "    high_end = [mean_num + step_num for mean_num, step_num in zip(mean, step_2)]\n",
    "\n",
    "    return low_end, high_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "aggregation = pd.read_csv('metrics.csv') \\\n",
    "        .assign(year=lambda row: row[\"Period Start\"].apply(lambda x: x[-4:])) \\\n",
    "        .assign(activity_year=lambda row: row[\"Activity\"] + \" (\" + row[\"year\"] + \")\") \\\n",
    "        .assign(average_days_to_complete_activity=lambda row: row[\"Average Days to Complete Activity\"].apply(lambda x: float(x))) \\\n",
    "        .groupby('activity_year') \\\n",
    "        .agg({\n",
    "             'Target Response Days': 'max', \n",
    "             'average_days_to_complete_activity': ['mean','std'],\n",
    "             'Activity' : 'count'\n",
    "            })\\\n",
    "        .reset_index()\n",
    "\n",
    "aggregation.columns = [' '.join(col).strip() for col in aggregation.columns.values]\n",
    "aggregation[\"conf_interval_bottom\"], aggregation[\"conf_interval_top\"] = confidence_interval_for_collection(sample_size=aggregation[\"Activity count\"], standard_deviation=aggregation[\"average_days_to_complete_activity std\"], mean=aggregation[\"average_days_to_complete_activity mean\"])\n",
    "\n",
    "aggregation[\"average_slippage\"] = aggregation[\"average_days_to_complete_activity mean\"] - aggregation[\"Target Response Days max\"]\n",
    "aggregation[\"slippage_corrected\"] = aggregation[\"conf_interval_top\"] - aggregation[\"Target Response Days max\"]\n",
    "\n",
    "aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the distance between two means statistically significant? \n",
    "\n",
    "It's possible they are, even if their confidence intervals overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test_for(num_samples_1, standard_deviation_1, mean_1, num_samples_2, standard_deviation_2, mean_2, confidence=0.95):\n",
    "    alpha = 1 – confidence\n",
    "    total_degrees_freedom = num_samples_1 + num_samples_2 – 2\n",
    "\n",
    "    t_distribution_number = –1 * t.ppf(alpha, total_degrees_freedom)\n",
    "\n",
    "    degrees_freedom_1 = num_samples_1 – 1\n",
    "    degrees_freedom_2 = num_samples_2 – 1\n",
    "    sum_of_squares_1 = (standard_deviation_1 ** 2) * degrees_freedom_1\n",
    "    sum_of_squares_2 = (standard_deviation_2 ** 2) * degrees_freedom_2\n",
    "\n",
    "    combined_variance = (sum_of_squares_1 + sum_of_squares_2) / (degrees_freedom_1 + degrees_freedom_2)\n",
    "    first_dividend_addend = combined_variance/float(num_samples_1)\n",
    "    second_dividend_addend = combined_variance/float(num_samples_2)\n",
    "\n",
    "    denominator = math.sqrt(first_dividend_addend + second_dividend_addend)\n",
    "    numerator = mean_1 – mean_2\n",
    "    t_value = float(numerator)/float(denominator)\n",
    "\n",
    "    accept_null_hypothesis = abs(t_value) < abs(t_distribution_number) #results are not significant\n",
    "\n",
    "    return accept_null_hypothesis, t_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Comparisons\n",
    "\n",
    "You may have 95% certainty that any one comparison isn’t statistically significant by fluke, but when you run a bunch of comparisons, eventually one of them will be a fluke. In fact, when you run 100 separate comparisons, your likelihood that none of the significant outcomes are flukes drops to a measly 1%.\n",
    "\n",
    "One solution is the **Bonferroni correction**: divide your intended p value by the number of comparisons you're running. This method gets criticism for being to harsh and missing important findings, so sometimes folks temper it by _lowering_ the P value, but not all the way to the Bonferroni correction prescription."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuity Errors\n",
    "\n",
    "This type of data representation error happens when someone misrepresents continuous data that does not fall into discrete categories (like body mass index) and either misrepresents it as discrete categories or interprets it in some way that isn’t true to the data. \n",
    "\n",
    "For example, with body mass index, we frequently see two categories: ‘normal weight’ and ‘overweight.’ So first of all, body mass index as a metric in the first place has been demonstrated to be a poor measure of health and fitness. So, we already have some issues. But let’s stick to continuity errors specifically. \n",
    "\n",
    "Frequently body mass index data gets categorized as ‘normal weight’ (24.9 or lower) or ‘overweight’ (above 24.9). Where is underweight? Also, what is the difference between a 24.8 and a 25.1? When these middle values get averaged together with extremes on either end, it looks like this 0.2 difference in the middle is a night and day difference. It’s not. We’re just representing a wide range with a tiny number of categories. \n",
    "\n",
    "It’s worth examining whether and why we need to categorize continuous variables before we do it. There are good reasons (get evenly sized buckets of points to compare means, draw meaningful visualizations, et cetera). But it’s not a default thing to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
